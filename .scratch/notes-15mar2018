http://metashare.tilde.com/repository/browse/probabilistic-bilingual-dictionaries-from-dgt-parallel-corpus-for-portuguese-english/f80ff33e7ef111e5aa3b001dd8b71c66a27b5e327bb541bfae4e094ae73ca006/
http://metashare.tilde.com/repository/search/?q=giza%2B%2B+dictionaries

https://github.com/pmarcis/dict-filtering/
https://github.com/pmarcis/mp-aligner

https://www.clarin.eu/showcase/old-bailey-corpus-20-1720-1913

https://github.com/actions-on-google

https://medium.com/@josecamachocollados/on-the-contribution-of-neural-networks-and-word-embeddings-in-natural-language-processing-c8bb1b85c61c

https://hanxiao.github.io/2018/01/10/Build-Cross-Lingual-End-to-End-Product-Search-using-Tensorflow/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=NLP%20News

https://github.com/faneshion/MatchZoo
MatchZoo is a toolkit for text matching. It was developed to facilitate the designing, comparing, and sharing of deep text matching models.

https://medium.freecodecamp.org/the-full-stack-guide-to-actions-for-google-assistant-e1765edd075b
https://medium.com/@zps270/designing-personas-for-google-action-bdfdcd2b4abc

https://github.com/urish/firebase-server

https://www.nbcnews.com/tech/social-media/now-available-more-200-000-deleted-russian-troll-tweets-n844731?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=NLP%20News
http://nodeassets.nbcnews.com/russian-twitter-trolls/tweets.csv
http://nodeassets.nbcnews.com/russian-twitter-trolls/users.csv

https://www.microsoft.com/en-us/research/uploads/prod/2018/03/final-achieving-human.pdf
Achieving Human Parity on Automatic
Chinese to English News Translation

http://wing.comp.nus.edu.sg/~antho/W/W17/W17-47.pdf

https://github.com/LUMII-AILab/Tezaurs
Open data from http://tezaurs.lv - an extensive dictionary and thesaurus of Latvian, comprising more than 290,000 lexical entries.

http://www.saeima.lv/lv/transcripts/view/461
http://cdn.tiesraides.lv/saeima.lv/20180125103901_saeima.lv.audio.01.1_1_0

http://www.saeima.lv/lv/likumdosana/saeimas-sedes

https://github.com/pdonald/latvian
Latvian is a C# library for natural language processing (NLP) tasks in Latvian.

Tokenization
Morphology
Part-of-speech tagging


https://github.com/PeterisP/morphology
 A Java library for analyzing morphology and part of speech information for Latvian words.


http://www.latvijasradio.lsm.lv/lv/piedavajumi/saeimas-sedes/?id=65
http://www.saeima.lv/lv/likumdosana/saeimas-sede/audio-translacijas
http://www.saeima.lv/lv/streams/steno/
http://www.saeima.lv/lv/likumdosana/saeimas-sede/video-translacijas
http://www.saeima.lv/lv/likumdosana/saeimas-sedes
http://www.saeima.lv/lv/transcripts/view/461

https://github.com/artetxem/vecmap

http://www.digitalhumanities.lv/resources/#

https://github.com/deepmipt/DeepPavlov

https://github.com/phil-el/phetools

https://github.com/aalto-speech/finnish-parliament-scripts/blob/master/align/asr_align_2_elan.py

https://github.com/MycroftAI/padatious/

https://github.com/google-research-datasets/wiki-reading

https://github.com/snipsco/sneetch_data
https://github.com/snipsco/rustling/blob/develop/src/train.rs
https://github.com/snipsco/rustling-ontology/
https://snips.ai/seeds/
https://github.com/snipsco/snips-nlu
https://github.com/snipsco/snips-nlu/blob/develop/snips_nlu_dataset/examples/getWeather.txt
https://medium.com/snips-ai/an-introduction-to-snips-nlu-the-open-source-library-behind-snips-embedded-voice-platform-b12b1a60a41a
https://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d
https://github.com/snipsco/awesome-snips
https://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d
https://medium.com/snips-ai/how-we-made-tensorflow-run-on-a-raspberry-pi-using-rust-7478f7a31329

https://github.com/MycroftAI/mimic2

https://opensource.com/article/16/11/open-source-amazon-echo-projects

https://github.com/RasaHQ/rasa_nlu
https://medium.com/rasa-blog/do-it-yourself-nlp-for-bot-developers-2e2da2817f3d

https://github.com/chartbeat-labs/textacy

https://github.com/sebischair/NLU-Evaluation-Corpora

https://www.youtube.com/watch?v=Mf1JFxTSr5Q
http://www.battleforums.com/threads/psychology-test-by-carl-jung.93250/

http://poleval.pl/index.php/results/
http://mozart.ipipan.waw.pl/~kkrasnowska/PolEval/src/
https://github.com/kwrobel-nlp/krnnt
https://github.com/wiktorwalentynowiczit/morphodita-pl-poleval

https://magenta.tensorflow.org/music-vae

https://github.com/facebook/duckling/blob/master/Duckling/Duration/EN/Rules.hs
https://github.com/facebook/duckling/blob/master/Duckling/Duration/GA/Rules.hs
https://github.com/facebook/duckling/blob/master/Duckling/Duration/PL/Rules.hs
https://github.com/facebook/duckling/blob/master/Duckling/Duration/PL/Corpus.hs
https://github.com/facebook/duckling/commit/b637deedc731f3f80b365cefbef4abb632a2d600

https://github.com/artetxem/vecmap

https://github.com/giuliopaci/SPro
https://github.com/rainlabs/stranger

https://github.com/mozilla/TTS/blob/master/layers/tacotron.py
https://www.reddit.com/r/MachineLearning/comments/845uji/d_are_the_hyperrealistic_results_of_tacotron2_and/
The issues in pronunciation are likely coming from issues in the dataset balance. There's a big difference between what a commercial TTS repo would use/read as normal text, and what a book has. See for example this paper. You can combat some of this with pronunciation hints in training as an easy workaround, but good data (in both quality, and database design) is the best approach.
http://ieeexplore.ieee.org/document/6709856/

Noise is good: https://arxiv.org/abs/1802.06901

[â€“]kkastner 9 points 4 days ago* 
The phoneme balance is pretty far off in LJ. If you read it, a lot of the sentences are like weird lists, or accounting registers or something. Remember most of these "industry grade" TTS databases were originally designed for concatenative synthesis - so you do things like care about sufficient coverage of every triphone and/or 5 gram, etc. These things will have a huge impact even if you train a parametric model on this dataset - the data has already been hand selected to be a representative support set for speech!

Check out Lyrebird's API for example - the sentences they have you read are not normal. There's a variety of reasons for it, but the key takeaway is that pure natural speech in some sense is like "imbalanced data", and you often want to do specific things to improve coverage of certain sounds.

Flaws in the model can't help, but I can guarantee r9y9 isn't making the silly DSP mistakes most other people tend to make (and there are a lot of pitfalls there to be avoided). Their work is some of the best, from both DSP and deep learning. I used their mgc implementation extensively in converting the WORLD vocoder to numpy (though it's ultimately too slow to be useful for much).

Griffin-Lim implementations (or more appropriately, how much overlap you use in your time-frequency transforms) can be another pitfall that most people don't even realize if they haven't worked with speech data or done DSP in and of itself before.

I really can't emphasize enough that the 50% overlap used in basically every package for default spectrogram settings is nowhere close to appropriate for TTS. The STRAIGHT vocoder Graves used in his original demo has a much, much higher overlap in time, something like 90-99%. And you can also have a lot of changes/improvements based on how you do windowing, or if you get funky and explore other time-frequency transforms.

The text side of these character based models is no joke, we had a much more difficult time on English than other languages such as Spanish and Romanian. If you change conditioning input from character based to "sound" or phoneme based, a lot of simpler models start working because you eliminate the much of the uncertainty in English pronunciation.

It isn't ideal, as we want to learn from characters but it goes to show that you have to put a ton of effort on the text side too, and a failure there can sink your whole model.

Obviously this DSP stuff (beyond not messing up downsampling, and quantization) shouldn't effect WaveNet reimplementation or other "purely time" models, but in WaveNet your text "data" has to go through a classic speech pipeline for feature extraction/approximate alignment (which is already insanely nasty, and has a ton of custom settings you could tweak if you knew it well), then train a bunch of mini-models using the very latest tricks.

See an example of just the text features (and not any combined text features...) from SPTK, or a slightly different one. Do you think those 186 different features between the datasets might matter (or be a bad idea) depending on dataset? I think so, but I don't know the text pipeline enough to tell.

Heiga Zen is one of the very top TTS researchers, who focused on parametric TTS since forever - he knows the tools like SPTK all the way to the very bottom, and wrote a bunch of serious C code for DSP and feature extract in there... and also has some cool results combining deep learning knowledge and classic TTS.

Then also take all that stuff you did with the text, make sure all the data feed and alignment is right and train a whole WaveNet on this, match architectures, etc. Remember that 32 GPUs likely means some kind of different optimizer than an off-the-shelf Adam, and you can see big differences in optimization with async gradient descent methods - often better stability and generalization. To fit the full WaveNet model AFAIK 2 GPUs is required - we couldn't ever fit the full model in a single GPU but maybe things have gotten bigger/better since then.

It's an enormous effort - I spent basically 6 months just trying to automate a wrapper around the speech/text extraction pipeline from Merlin which was already more straightforward than anything I had found before then. The code for that script (which heavily leverages ~4 or 5 different crufty C packages internally) dwarfs my own library code for all the component parts of a model like the "reader" of char2wav, including several model setups.

If you want some code you can run yourself today, also check out Facebook's Loop. It can get pretty high fidelity results (to my foreign/non-speaker ears at least) on certain datasets, but again data is everything. They (FB) also had a recent follow-up paper, but I don't know if code is available yet.

TL;DR

Progress in speech synthesis with neural networks has come at an insanely rapid pace, but make no mistake - the pipeline is more involved than many other areas. Expect that replication will be difficult, especially without access to the original data. Data is everything in TTS.

Facebook's Loop: https://github.com/facebookresearch/loop
on certain datasets: https://twitter.com/hiromu1996/status/934758563418742784
Voiceloop [ARXIV: 1705.03122] + jsut [arXiv: 1711.00354] I try Japanese TTS, but the intonation is still subtle https://soundcloud.com/hiromu-yakura/sets/voiceloop-jsut-epoch-53 â€¦



[â€“]kkastner 11 points 4 days ago* 
Definitely yes. I usually start with just the preproc. Even downsampling / mu-law encoding can cause aliasing or bit-noise if done inappropriately. Let alone more complicated things like STFT (what is the overlap? - I recommend > 80% personally - what is the window? is the griffin-lim implementation correct/converging?). I have spent a lot of time in my life debugging models, when I should have been re-checking my data processing.


https://towardsdatascience.com/deep-neural-network-implemented-in-pure-sql-over-bigquery-f3ed245814d3

https://www.tensorflow.org/extend/new_data_formats

https://en.wikipedia.org/wiki/Comparison_of_distributed_file_systems
https://github.com/quantcast/qfs
https://github.com/orifs/ori

https://github.com/aquynh/capstone

https://github.com/antlr/grammars-v4/blob/master/vb6/VisualBasic6.g4

https://github.com/brainsickcc/libvbgui/blob/wip/lib.c
(Affero (ugh) VB6 compiler - GUI lib)


https://arxiv.org/abs/1803.04831
Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN

https://arxiv.org/abs/1803.04596
Automatic Detection of Online Jihadist Hate Speech

https://github.com/resonance-audio

https://www.reddit.com/r/MachineLearning/comments/84r7ws/d_to_fine_tune_word_embeddings_or_not/

https://blogs.technet.microsoft.com/machinelearning/2018/03/14/comparing-deep-learning-frameworks-a-rosetta-stone-approach/
https://github.com/ilkarman/DeepLearningFrameworks

https://www.tensorflow.org/extend/add_filesys

https://arxiv.org/pdf/1712.09444.pdf
Letter-Based Speech Recognition with Gated ConvNets


https://www.reddit.com/r/MachineLearning/comments/85cwiu/d_wellwritten_paper_examples/

https://arxiv.org/abs/1803.03635
The Lottery Ticket Hypothesis: Training Pruned Neural Networks

https://arxiv.org/pdf/1608.03542.pdf
WIKIREADING: A Novel Large-scale Language Understanding Task over
Wikipedia

http://tomkenter.nl/pdf/kenter_byte-level_2018.pdf
https://github.com/google-research-datasets/wiki-reading

https://www.reddit.com/r/MachineLearning/comments/858c88/d_does_anyone_use_dropout_anymore/

https://medium.com/@Synced/baidu-apollo-releases-massive-self-driving-dataset-teams-up-with-berkeley-deepdrive-5e785ab4053b
http://apolloscape.auto/index.html

https://www.reddit.com/r/MachineLearning/comments/7zb2jm/n_baidu_ai_can_clone_your_voice_in_seconds/
https://github.com/Kyubyong/cross_vc

https://github.com/Kyubyong/speaker_adapted_tts
https://github.com/Kyubyong/dc_tts

https://github.com/tkipf/relational-gcn

https://github.com/DanielSWolf/rhubarb-lip-sync
https://github.com/tracend/papagayo/

https://github.com/MSiam/TFSegmentation

https://github.com/AKSW/NSpM
Neural SPARQL

https://github.com/azadis/MC-GAN
Multi-Content GAN for Few-Shot Font Style Transfer at CVPR 2018 http://bair.berkeley.edu/blog/2018/03â€¦
http://bair.berkeley.edu/blog/2018/03/13/mcgan/


https://www.youtube.com/watch?v=uR-_8SGhYw8
Irish, no subs, clear for lipreading

https://github.com/Jekub/Wapiti
A simple and fast discriminative sequence labeling toolkit ( http://wapiti.limsi.fr )
https://github.com/kermitt2/grobid
A machine learning software for extracting information from scholarly documents
https://github.com/allenai/science-parse
Library and tools for extracting metadata from PDFs

https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_binarynet_mnist_cnn.py

https://petewarden.com/2018/03/19/the-machine-learning-reproducibility-crisis/
https://github.com/polyaxon/polyaxon

https://github.com/allenai/ontoemma
An ontology matcher for matching entities between knowledgebases

https://arxiv.org/pdf/1803.07038.pdf
Controlling Decoding for More Abstractive Summaries
with Copy-Based Networks

https://github.com/lincolnhard/head-pose-estimation/blob/master/video_test_shape.cpp

dynamic binary analysis via platform emulation https://usercorn.party
https://github.com/lunixbochs/usercorn

https://github.com/reactos/reactos
https://www.reactos.org/wiki/VirtualBox
https://www.reactos.org/wiki/QEMU

https://github.com/rust-lang/rust-by-example
https://rustbyexample.com/

https://github.com/kan-bayashi/PytorchWaveNetVocoder


/home/jim/disk/Playing/sphinx-alignment/cmusphinx-alignment-example
/home/jim/disk/Playing/lip-reading-deeplearning

diff --git a/.bash_history b/.bash_history
index 4cabdcd..0422442 100644
--- a/.bash_history
+++ b/.bash_history
@@ -1998,3 +1998,62 @@ vi /tmp/wavlists
 find . -name 'CI0001CDNamedEntities0*ogg' | sh grepconv.sh 
 sh grepconv.sh 
 find . -name 'CI0001CDNamedEntities0*ogg' -exec bash convfile.sh {} asr_data_irish/data/audio/nnc_named_entities/wav \;
+cd asr_data_irish/
+find . -name 'corpus*' -exec cat {} \;
+find . -name 'corpus*' -exec cat {} \;|wc
+ls
+ls data/
+ls audio
+ls data/audio/
+mkdir -p data/audio/nnc_named_entities/wav/
+grep CI0001CDNamedEntities02 /tmp/wavlists 
+grep CI0001CDNamedEntities02 /tmp/wavlists |while read i;do file=$(echo $i|awk -F/ '{print $NF}');out=$(basename $file .ogg).wav;echo $out;done
+grep CI0001CDNamedEntities02 /tmp/wavlists |while read i;do file=$(echo $i|awk -F/ '{print $NF}');out=$(basename $file .ogg).wav;echo $i $out;done
+find . -name 'corpus*' -exec cat {} \;|wc
+find . -name 'corpus*' 
+less 
+less ./data/synthesis_recordings/nnc_named_entities/corpusfile.txt
+less ~/bin/convert-mp3.sh 
+less ./data/synthesis_recordings/nnc_named_entities/corpusfile.txt
+ls -al data/audio/nnc_named_entities/wav/
+rm data/audio/nnc_named_entities/wav/CI0001CDNamedEntities02_0*
+ls -al data/audio/nnc_named_entities/wav/
+ls -al data/audio/nnc_named_entities/wav/|grep 0170
+grep 0170 /tmp/wavlists 
+grep 0170 /tmp/wavlists |grep nnc
+ffplay /home/jim/disk/Playing/Corpora/ga_MU/nnc/CDNamedEntities02/ogg/CI0001CDNamedEntities02_0170.ogg 
+ls -al data/audio/nnc_named_entities/wav/|grep 0170
+ls -al data/audio/nnc_named_entities/wav/
+ffplay data/audio/nnc_named_entities/wav/CI0001CDNamedEntities02_0314.wav
+ls -al data/audio/nnc_named_entities/wav/|grep 0170
+ls
+less scripts/makeKaldiFiles.py 
+python scripts/makeKaldiFiles.py harald  ./data/synthesis_recordings/nnc_named_entities/corpusfile.txt
+ls data/audio/nnc_named_entities/wav/CI0001CDNamedEntities0*|wc
+less /home/jim/disk/Playing/kaldi/egs/harald/data/test/utt2spk
+less /home/jim/disk/Playing/kaldi/egs/harald/data/test/wav.scp 
+less /home/jim/disk/Playing/kaldi/egs/harald/data/local/dict/lexicon.txt 
+less ./data/synthesis_recordings/nnc_named_entities/corpusfile.txt
+ffplay data/audio/nnc_named_entities/wav/CI0001CDNamedEntities01_0170.wav 
+less /home/jim/disk/Playing/kaldi/egs/harald/data/local/dict/lexicon.txt 
+less ./data/synthesis_recordings/nnc_named_entities/corpusfile.txt
+ffplay data/audio/nnc_named_entities/wav/CI0001CDNamedEntities02_0035.wav 
+vi ./data/synthesis_recordings/nnc_named_entities/corpusfile.txt
+ffplay data/audio/nnc_named_entities/wav/CI0001CDNamedEntities01_0191.wav 
+vi ./data/synthesis_recordings/nnc_named_entities/corpusfile.txt
+ffplay data/audio/nnc_named_entities/wav/CI0001CDNamedEntities02_0076.wav 
+vi ./data/synthesis_recordings/nnc_named_entities/corpusfile.txt
+ffplay data/audio/nnc_named_entities/wav/CI0001CDNamedEntities02_0218.wav 
+less /tmp/68.txt 
+echo $PWD
+history -a
diff --git a/.bash_history b/.bash_history
index 2c1a08d..4b0819d 100644
+find . -name corpusfile.txt
+less ./data/mul_mo_sceal_fein/corpusfile.txt
+mkdir data/audio/mul_mo_sceal_fein/
+man ln
+less /tmp/audio-file-locs 
+ln -sd ../ga_MU/mo_sgeal_fein_CORK/corpus/wav/ data/audio/mul_mo_sceal_fein/wav
+ls data/audio/mul_mo_sceal_fein/wav
+ls -al data/audio/mul_mo_sceal_fein/wav
+ls -al data/audio/mul_mo_sceal_fein/wav/
+file data/audio/mul_mo_sceal_fein/wav 
+rm data/audio/mul_mo_sceal_fein/wav 
+ln -sd $PWD/../ga_MU/mo_sgeal_fein_CORK/corpus/wav/ data/audio/mul_mo_sceal_fein/wav
+ls -al data/audio/mul_mo_sceal_fein/wav/
+find . -name corpusfile.txt|head
+python scripts/makeKaldiFiles.py ./data/mul_mo_sceal_fein/corpusfile.txt
+python scripts/makeKaldiFiles.py harald ./data/mul_mo_sceal_fein/corpusfile.txt
+ls data/audio/mul_mo_sceal_fein/wav/tcd_ga_mu_mnl_msf_0001.wav 
+#ln -sd $PWD/../ga_MU/mo_sgeal_fein_CORK/corpus/wav/ data/audio/mul_mo_sceal_fein/wav
+rm data/audio/mul_mo_sceal_fein/wav
+#cp ../ga_MU/mo_sgeal_fein_CORK/corpus/wav/* data/audio/mul_mo_sceal_fein/wav
+mkdir data/audio/mul_mo_sceal_fein/wav
+cp ../ga_MU/mo_sgeal_fein_CORK/corpus/wav/* data/audio/mul_mo_sceal_fein/wav
+python scripts/makeKaldiFiles.py harald ./data/mul_mo_sceal_fein/corpusfile.txt
+find . -name corpusfile.txt
+find . -name corpusfile.txt -exec cat {} \;
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk 'BEGIN{FS=OFS="/"}{$NF="";print}'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk 'BEGIN{FS=OFS="/"}{$NF="";print}'|sort|uniq
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk 'BEGIN{FS=OFS="/"}{$NF="";print}'|sort|uniq|sed -e 's/\.\.\/\.\.\///'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk 'BEGIN{FS=OFS="/"}{$NF="";print}'|sort|uniq|sed -e 's/\.\.\/\.\.\///;s/\.\.\///;s/asrdata\//'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk 'BEGIN{FS=OFS="/"}{$NF="";print}'|sort|uniq|sed -e 's/\.\.\/\.\.\///;s/\.\.\///;s/asrdata\///'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk 'BEGIN{FS=OFS="/"}{$NF="";print}'|sort|uniq|sed -e 's/\.\.\/\.\.\///;s/\.\.\///;s/asrdata\///'|less
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk 'BEGIN{FS=OFS="/"}{$NF="";print}'|sort|uniq|sed -e 's/\.\.\/\.\.\///;s/\.\.\///;s/asrdata\///'|while read i;do mkdir -p  data/$i;done
+ls data/audio/
+less /tmp/audio-file-locs 
+tree data/audio/
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|sort|uniq|sed -e 's/\.\.\/\.\.\///;s/\.\.\///;s/asrdata\///'|while read i;do if [ -e data/$i ];then echo $i >> /tmp/iss;fi;done
+less /tmp/iss 
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|sort|uniq|sed -e 's/\.\.\/\.\.\///;s/\.\.\///;s/asrdata\///'|while read i;do if [ ! -e data/$i ];then echo $i >> /tmp/isnot;fi;done
+wc -l /tmp/isnot 
+cat /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); find ../ga_* -name $fname;done
+cat /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); grep $fname /tmp/datafiles ;done
+cat /tmp/isnot 
+grep seanchas_rann_na_feirste /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); from=$(grep $fname /tmp/datafiles);  echo cp $from $i ;done
+grep seanchas_rann_na_feirste /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); from=$(grep $fname /tmp/datafiles);  echo cp $from data/$i ;done
+grep seanchas_rann_na_feirste /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); from=$(grep $fname /tmp/datafiles);  cp $from data/$i ;done
+vi /tmp/isnot 
+grep piarsach /tmp/isnot 
+grep piarsach /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); from=$(grep $fname /tmp/datafiles);  cp $from data/$i ;done
+grep piarsach /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); from=$(grep $fname /tmp/datafiles); echo cp $from data/$i ;done
+grep piarsach /tmp/isnot|tail -n 1 |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); from=$(grep $fname /tmp/datafiles); echo cp $from data/$i ;done
+grep piarsach /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); from=$(grep $fname /tmp/datafiles|tail -n 1); echo cp $from data/$i ;done
+grep piarsach /tmp/isnot |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); from=$(grep $fname /tmp/datafiles|tail -n 1); cp $from data/$i ;done

+grep makeKaldiFiles.py ~/.bash_history 
+find . -name corpusfile.txt
+less ./data/mul_mo_sceal_fein/corpusfile.txt
+tail ./data/mul_mo_sceal_fein/corpusfile.txt
+ls
+ls ../ga_MU/mo_sgeal_fein_CORK/wav/
+tree ../ga_MU/mo_sgeal_fein_CORK/
+tree ../ga_MU/mo_sgeal_fein_CORK/|less
+find ../ga_MU/mo_sgeal_fein_CORK/ -name '*wav'
+find . -name corpusfile.txt
+find . -name corpusfile.txt|wc
+find . -name corpusfile.txt -exec cat {} \;
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk -F'/' '{print $NF}'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk -F'/' '{print $NF}'|sed -e 's/wav$/*/'
+find . -name corpusfile.txt -exec cat {} \;|awk -F'\t' '{print $3}'|awk -F'/' '{print $NF}'|sed -e 's/wav$/*/' > /tmp/audiofiles-asr
+cat /tmp/audiofiles-asr |while read i;do find .. -name $i;done
+cat /tmp/audiofiles-asr |while read i;do find .. -name $i;done >> /tmp/audio-file-locs
+less /tmp/audio-file-locs 
+ls
+find ../ga_* ../UISC -name '*.wav' -or -name '*.ogg'
+find ../ga_* ../UISC -name '*.wav' -or -name '*.ogg' > /tmp/datafiles
+cat /tmp/isnot|tail -n 30 |while read i;do fname=$(echo $i|awk -F/ '{print $NF}'); grep $fname /tmp/datafiles ;done
+cat /tmp/isnot|head
+find . -name corpusfile.txt -exec cat {} \;
+find . -name corpusfile.txt -exec cat {} \;|grep idam

/home/jim/public_html/failteoir
