from datasets import load_dataset
dataset = load_dataset("oscar", language="hu", split="train")
import re
chars_to_ignore_regex = """[",", "?", "¿", ".", "!", "¡", ";", "；", ":", '""', "%", '"', "�", "ʿ", "·", "჻", "~", "՞",
                   "؟", "،", "।", "॥", "«", "»", "„", "“", "”", "「", "」", "‘", "’", "《", "》", "(", ")", "[", "]",
                   "{", "}", "=", "`", "_", "+", "<", ">", "…", "–", "°", "´", "ʾ", "‹", "›", "©", "®", "—", "→", "。",
                   "、", "﹂", "﹁", "‧", "～", "﹏", "，", "｛", "｝", "（", "）", "［", "］", "【", "】", "‥", "〽",
                   "『", "』", "〝", "〟", "⟨", "⟩", "〜", "：", "！", "？", "♪", "؛", "/", "\\", "º", "−", "^", "ʻ", "ˆ"]"""
def extract_text(batch):
  text = batch["text"]
  batch["text"] = re.sub(chars_to_ignore_regex, "", text.lower())
  return batch
dataset = dataset.map(extract_text, remove_columns="id")
with open("hungarian.txt", "w") as f:
	for line in dataset["text"]:
	f.write(line + "\n")
dataset["text"]
dataset["text"][0]
with open("hungarian.txt", "w") as f:
	for line in dataset["text"]:
		f.write(line + "\n")
from transformers import pipeline
pipe = pipeline(model="jonatasgrosman/wav2vec2-large-xlsr-53-polish", framework="pt")
from transformers import pipeline
pipe = pipeline(model="jonatasgrosman/wav2vec2-large-xlsr-53-polish", framework="pt")
from transformers import pipeline
pipe = pipeline(model="jonatasgrosman/wav2vec2-large-xlsr-53-polish", framework="pt")
file = "z-wichrow-i-hal-z-tatr-krzak-dzikiej-rozy-w-ciemnych-smreczy_000.mp3"
output = pipe(file, chunk_length_s=10, return_timestamps="word")
file = "zloczynca_000.mp3"
output = pipe(file, chunk_length_s=10, return_timestamps="word")
from pathlib import Path
Path("zaczarowana-krolewna_000.json").exists()
output = pipe(file, chunk_length_s=10, return_timestamps="word", device=0)
from transformers import pipeline
pipe = pipeline(model="jonatasgrosman/wav2vec2-large-xlsr-53-polish", framework="pt", device=0)
SKIP = "ksiega-dzungli_001_czesc-i.mp3"
import glob
import json
from pathlib import Path
for file in glob.glob("*.mp3"):
    jsonfile = file.replace(".mp3", ".json")
    if Path(jsonfile).exists() or file in SKIP:
            continue
    print(file)  
    output = pipe(file, chunk_length_s=10, return_timestamps="word")
    with open(jsonfile, "w") as outf:
            json.dump(output, outf)
for file in glob.glob("*.mp3"):
    jsonfile = file.replace(".mp3", ".json")
    if Path(jsonfile).exists() or file in SKIP:
            continue
    print(file)  
    output = pipe(file, chunk_length_s=10, return_timestamps="word")
    with open(jsonfile, "w") as outf:
            json.dump(output, outf)
import cairo
from pydub import AudioSegment
audio = AudioSegment("/tmp/test.wav")
audio = AudioSegment.from_wav("/tmp/test.wav")
start = int(5.32 * 1000)
start
end = int(9.1 * 1000)
end
seg = audio[start:end]
from pydub.silence import detect_silence
detect_silence(seg)
seg.duration_seconds
detect_silence(seg, 100)
detect_silence(audio[start:end], 100)
detect_silence(audio[start:end], 50)
import torch
£      model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)
model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)
#      (get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils
(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils
help(read_audio)
read_audio("/tmp/test.wav")
seg.shape
seg.raw_data
seg.get_array_of_samples()
from pydub import AudioSegment
import torch
import soundfile as sf
